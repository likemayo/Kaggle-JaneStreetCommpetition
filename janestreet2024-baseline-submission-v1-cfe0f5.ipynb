{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8612e908",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:03:18.665271Z",
     "iopub.status.busy": "2025-01-11T16:03:18.664731Z",
     "iopub.status.idle": "2025-01-11T16:03:20.426649Z",
     "shell.execute_reply": "2025-01-11T16:03:20.425649Z"
    },
    "papermill": {
     "duration": 1.768139,
     "end_time": "2025-01-11T16:03:20.428602",
     "exception": false,
     "start_time": "2025-01-11T16:03:18.660463",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!cp -rf /kaggle/input/model2/jswinwinwin/* ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb3eed9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:03:20.436078Z",
     "iopub.status.busy": "2025-01-11T16:03:20.435466Z",
     "iopub.status.idle": "2025-01-11T16:04:00.331713Z",
     "shell.execute_reply": "2025-01-11T16:04:00.330806Z"
    },
    "papermill": {
     "duration": 39.903973,
     "end_time": "2025-01-11T16:04:00.335733",
     "exception": false,
     "start_time": "2025-01-11T16:03:20.431760",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./rtdl_num_embeddings-0.0.11-py3-none-any.whl\n",
      "Requirement already satisfied: torch<3,>=1.12 in /opt/conda/lib/python3.10/site-packages (from rtdl-num-embeddings==0.0.11) (2.4.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (3.15.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (4.12.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (2024.6.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch<3,>=1.12->rtdl-num-embeddings==0.0.11) (1.3.0)\n",
      "Installing collected packages: rtdl-num-embeddings\n",
      "Successfully installed rtdl-num-embeddings-0.0.11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.system(\"pip install rtdl_num_embeddings-0.0.11-py3-none-any.whl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b3bbf13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:00.342743Z",
     "iopub.status.busy": "2025-01-11T16:04:00.342449Z",
     "iopub.status.idle": "2025-01-11T16:04:04.406613Z",
     "shell.execute_reply": "2025-01-11T16:04:04.405714Z"
    },
    "papermill": {
     "duration": 4.069854,
     "end_time": "2025-01-11T16:04:04.408623",
     "exception": false,
     "start_time": "2025-01-11T16:04:00.338769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2718bd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:04.416387Z",
     "iopub.status.busy": "2025-01-11T16:04:04.415745Z",
     "iopub.status.idle": "2025-01-11T16:04:04.426308Z",
     "shell.execute_reply": "2025-01-11T16:04:04.425494Z"
    },
    "papermill": {
     "duration": 0.016086,
     "end_time": "2025-01-11T16:04:04.427941",
     "exception": false,
     "start_time": "2025-01-11T16:04:04.411855",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"mv winwinjs.sobak winwinjs.so\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac320835",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:04.436505Z",
     "iopub.status.busy": "2025-01-11T16:04:04.436277Z",
     "iopub.status.idle": "2025-01-11T16:04:08.876092Z",
     "shell.execute_reply": "2025-01-11T16:04:08.875379Z"
    },
    "papermill": {
     "duration": 4.446954,
     "end_time": "2025-01-11T16:04:08.878066",
     "exception": false,
     "start_time": "2025-01-11T16:04:04.431112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from winwinjs import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5e28024",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:08.886089Z",
     "iopub.status.busy": "2025-01-11T16:04:08.885632Z",
     "iopub.status.idle": "2025-01-11T16:04:08.895650Z",
     "shell.execute_reply": "2025-01-11T16:04:08.895032Z"
    },
    "papermill": {
     "duration": 0.015755,
     "end_time": "2025-01-11T16:04:08.897275",
     "exception": false,
     "start_time": "2025-01-11T16:04:08.881520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import r2_score\n",
    "import pandas as pd\n",
    "import math\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "from tabm_reference import Model, make_parameter_groups\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import kaggle_evaluation.jane_street_inference_server\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f2de6a2d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:08.904878Z",
     "iopub.status.busy": "2025-01-11T16:04:08.904512Z",
     "iopub.status.idle": "2025-01-11T16:04:12.333451Z",
     "shell.execute_reply": "2025-01-11T16:04:12.332545Z"
    },
    "papermill": {
     "duration": 3.434989,
     "end_time": "2025-01-11T16:04:12.335495",
     "exception": false,
     "start_time": "2025-01-11T16:04:08.900506",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import joblib\n",
    "with open(\"wwmodellist.pkl\", \"rb\") as fp:\n",
    "    [data_stats,xgb_model,xgb_model2,features,lgb1,cat1,xgb1,_,_] = pickle.load(fp)\n",
    "\n",
    "\n",
    "from pytorch_lightning import LightningModule\n",
    "feature_list = [f\"feature_{idx:02d}\" for idx in range(79) if idx != 61]\n",
    "\n",
    "target_col = \"responder_6\" \n",
    "\n",
    "feature_test = feature_list \\\n",
    "                + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "\n",
    "feature_cat = [\"feature_09\", \"feature_10\", \"feature_11\"]\n",
    "feature_cont = [item for item in feature_test if item not in feature_cat]\n",
    "\n",
    "batch_size = 8192\n",
    "\n",
    "std_feature = [i for i in feature_list if i not in feature_cat] + [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "\n",
    "means = data_stats['mean']\n",
    "stds = data_stats['std']\n",
    "\n",
    "def standardize(df, feature_cols, means, stds):\n",
    "    return df.with_columns([\n",
    "        ((pl.col(col) - means[col]) / stds[col]).alias(col) for col in feature_cols\n",
    "    ])\n",
    "category_mappings = {'feature_09': {2: 0, 4: 1, 9: 2, 11: 3, 12: 4, 14: 5, 15: 6, 25: 7, 26: 8, 30: 9, 34: 10, 42: 11, 44: 12, 46: 13, 49: 14, 50: 15, 57: 16, 64: 17, 68: 18, 70: 19, 81: 20, 82: 21},\n",
    " 'feature_10': {1: 0, 2: 1, 3: 2, 4: 3, 5: 4, 6: 5, 7: 6, 10: 7, 12: 8},\n",
    " 'feature_11': {9: 0, 11: 1, 13: 2, 16: 3, 24: 4, 25: 5, 34: 6, 40: 7, 48: 8, 50: 9, 59: 10, 62: 11, 63: 12, 66: 13,\n",
    "  76: 14, 150: 15, 158: 16, 159: 17, 171: 18, 195: 19, 214: 20, 230: 21, 261: 22, 297: 23, 336: 24, 376: 25, 388: 26, 410: 27, 522: 28, 534: 29, 539: 30},\n",
    " 'symbol_id': {0: 0, 1: 1, 2: 2, 3: 3, 4: 4, 5: 5, 6: 6, 7: 7, 8: 8, 9: 9, 10: 10, 11: 11, 12: 12, 13: 13, 14: 14, 15: 15, 16: 16, 17: 17, 18: 18, 19: 19,\n",
    "  20: 20, 21: 21, 22: 22, 23: 23, 24: 24, 25: 25, 26: 26, 27: 27, 28: 28, 29: 29, 30: 30, 31: 31, 32: 32, 33: 33, 34: 34, 35: 35, 36: 36, 37: 37, 38: 38},\n",
    " 'time_id' : {i : i for i in range(968)}}\n",
    "\n",
    "def encode_column(df, column, mapping):\n",
    "    max_value = max(mapping.values())  \n",
    "\n",
    "    def encode_category(category):\n",
    "        return mapping.get(category, max_value + 1)  \n",
    "    \n",
    "    return df.with_columns(\n",
    "        pl.col(column).map_elements(encode_category).alias(column)\n",
    "    )\n",
    "class R2Loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(R2Loss, self).__init__()\n",
    "\n",
    "    def forward(self, y_pred, y_true):\n",
    "        mse_loss = torch.sum((y_pred - y_true) ** 2)\n",
    "        var_y = torch.sum(y_true ** 2)\n",
    "        loss = mse_loss / (var_y + 1e-38)\n",
    "        return loss\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, n_cont_features, cat_cardinalities, n_classes, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.k = 16\n",
    "        self.model = Model(\n",
    "                n_num_features=n_cont_features,\n",
    "                cat_cardinalities=cat_cardinalities,\n",
    "                n_classes=n_classes,\n",
    "                backbone={\n",
    "                    'type': 'MLP',\n",
    "                    'n_blocks': 3 ,\n",
    "                    'd_block': 512,\n",
    "                    'dropout': 0.25,\n",
    "                },\n",
    "                bins=None,\n",
    "                num_embeddings= None,\n",
    "                arch_type='tabm',\n",
    "                k=self.k,\n",
    "            )\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.training_step_outputs = []\n",
    "        self.validation_step_outputs = []\n",
    "        self.loss_fn = R2Loss()\n",
    "        # self.loss_fn = weighted_mse_loss\n",
    "\n",
    "    def forward(self, x_cont, x_cat):\n",
    "        return self.model(x_cont, x_cat).squeeze(-1)\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x_cont,x_cat, y, w , w_y= batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.training_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x_cont,x_cat, y, w, w_y = batch\n",
    "        x_cont = x_cont + torch.randn_like(x_cont) * 0.02\n",
    "        y_hat = self(x_cont, x_cat)\n",
    "        # loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k), w_y.repeat_interleave(self.k))\n",
    "        loss = self.loss_fn(y_hat.flatten(0, 1), y.repeat_interleave(self.k))\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, prog_bar=True, logger=True, batch_size=x_cont.size(0))\n",
    "        self.validation_step_outputs.append((y_hat.mean(1), y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.AdamW(make_parameter_groups(self.model), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        # scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=5,\n",
    "        #                                                        verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            # 'lr_scheduler': {\n",
    "            #     'scheduler': scheduler,\n",
    "            #     'monitor': 'val_r_square',\n",
    "            # }\n",
    "        }\n",
    "\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "\n",
    "        y = torch.cat([x[1] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        prob = torch.cat([x[0] for x in self.training_step_outputs]).detach().cpu().numpy()\n",
    "        weights = torch.cat([x[2] for x in self.training_step_outputs]).cpu().numpy()\n",
    "        # r2_training\n",
    "        train_r_square = r2_val(y, prob, weights)\n",
    "        self.log(\"train_r_square\", train_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.training_step_outputs.clear()\n",
    "\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n",
    "        \n",
    "class custom_args():\n",
    "    def __init__(self):\n",
    "        self.usegpu = True\n",
    "        self.gpuid = 0\n",
    "        self.seed = 42\n",
    "        self.model = 'nn'\n",
    "        self.use_wandb = False\n",
    "        self.project = 'js-tabm-with-lags'\n",
    "        self.dname = \"./input_df/\"\n",
    "        self.loader_workers = 10   \n",
    "        self.bs = 8192\n",
    "        self.lr = 1e-3\n",
    "        self.weight_decay = 8e-4\n",
    "        self.n_cont_features = 84\n",
    "        self.n_cat_features = 5\n",
    "        self.n_classes = None\n",
    "        self.cat_cardinalities = [23, 10, 32, 40, 969]\n",
    "        self.patience = 7\n",
    "        self.max_epochs = 10\n",
    "        self.N_fold = 5\n",
    "\n",
    "\n",
    "my_args = custom_args()\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# modeltrans = NN.load_from_checkpoint('tabmodel.ckpt').to(device)\n",
    "# modeltrans = NN.load_from_checkpoint('tabmodel.ckpt').to(device)\n",
    "# modeltrans = NN.load_from_checkpoint('tabmodel.ckpt').to(device)\n",
    "modeltrans = NN.load_from_checkpoint('tabmodel.ckpt').to(device)\n",
    "\n",
    "\n",
    "lags_ : pl.DataFrame | None = None\n",
    "\n",
    "lags_history = None\n",
    "\n",
    "def predict_tabm(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_, lags_history\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "    \n",
    "    for col in feature_cat + ['symbol_id', 'time_id']:\n",
    "        test = encode_column(test, col, category_mappings[col])\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    \n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    time_id = test.select(\"time_id\").to_numpy()[0]\n",
    "    timie_id_array = test.select(\"time_id\").to_numpy()[:, 0]\n",
    "    \n",
    "    \n",
    "    if time_id == 0:\n",
    "        lags = lags.with_columns(pl.col('time_id').cast(pl.Int64))\n",
    "        lags = lags.with_columns(pl.col('symbol_id').cast(pl.Int64))\n",
    "    \n",
    "        lags_history = lags\n",
    "        lags = lags.filter(pl.col(\"time_id\") == 0)\n",
    "        \n",
    "        \n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "    else:\n",
    "        lags = lags_history.filter(pl.col(\"time_id\") == time_id)\n",
    "        test = test.join(lags, on=[\"time_id\", \"symbol_id\"],  how=\"left\")\n",
    "\n",
    "    \n",
    "    test = test.with_columns([\n",
    "        pl.col(col).fill_null(0) for col in feature_list + [f\"responder_{idx}_lag_1\" for idx in range(9)] \n",
    "    ])\n",
    "\n",
    "    test = standardize(test, std_feature, means, stds)\n",
    "\n",
    "\n",
    "    X_test = test[feature_test].to_numpy()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32).to(device)\n",
    "\n",
    "    symbol_tensor = torch.tensor(symbol_ids, dtype=torch.float32).to(device)\n",
    "    time_tensor = torch.tensor(timie_id_array, dtype=torch.float32).to(device)\n",
    "    X_cat = X_test_tensor[:, [9, 10, 11]]\n",
    "    X_cont = X_test_tensor[:, [i for i in range(X_test_tensor.shape[1]) if i not in [9, 10, 11]]]\n",
    "    # X_cont = X_cont + torch.randn_like(X_cont) * 0.02\n",
    "\n",
    "    X_cat = (torch.concat([X_cat, symbol_tensor.unsqueeze(-1), time_tensor.unsqueeze(-1)], axis=1)).to(torch.int64)\n",
    "    \n",
    "\n",
    "    modeltrans.eval()\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        outputs = modeltrans(X_cont, X_cat)\n",
    "        # Assuming the model outputs a tensor of shape (batch_size, 1)\n",
    "        preds = outputs.squeeze(-1).cpu().numpy()\n",
    "        preds = preds.mean(1)\n",
    "    \n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    # The predict function must return a DataFrame\n",
    "    assert isinstance(predictions, pl.DataFrame | pd.DataFrame)\n",
    "    # with columns 'row_id', 'responer_6'\n",
    "    assert list(predictions.columns) == ['row_id', 'responder_6']\n",
    "    # and as many rows as the test data.\n",
    "    assert len(predictions) == len(test)\n",
    "\n",
    "    return preds\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "937af931",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:12.343803Z",
     "iopub.status.busy": "2025-01-11T16:04:12.343021Z",
     "iopub.status.idle": "2025-01-11T16:04:12.348333Z",
     "shell.execute_reply": "2025-01-11T16:04:12.347606Z"
    },
    "papermill": {
     "duration": 0.010984,
     "end_time": "2025-01-11T16:04:12.349973",
     "exception": false,
     "start_time": "2025-01-11T16:04:12.338989",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import os, gc\n",
    "from tqdm.auto import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from pytorch_lightning import (LightningDataModule, LightningModule, Trainer)\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, Timer\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18abe854",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:12.357733Z",
     "iopub.status.busy": "2025-01-11T16:04:12.357429Z",
     "iopub.status.idle": "2025-01-11T16:04:12.372846Z",
     "shell.execute_reply": "2025-01-11T16:04:12.372086Z"
    },
    "papermill": {
     "duration": 0.021101,
     "end_time": "2025-01-11T16:04:12.374266",
     "exception": false,
     "start_time": "2025-01-11T16:04:12.353165",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None\n",
    "\n",
    "import kaggle_evaluation.jane_street_inference_server\n",
    "class CONFIG2:\n",
    "    seed = 42\n",
    "    target_col = \"responder_6\"\n",
    "    # feature_cols = [\"symbol_id\", \"time_id\"] + [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    feature_cols = [f\"feature_{idx:02d}\" for idx in range(79)]+ [f\"responder_{idx}_lag_1\" for idx in range(9)]\n",
    "    \n",
    "    model_paths = [\n",
    "        \"nnmodels\",\n",
    "        \"result.pkl\",\n",
    "    ]\n",
    "\n",
    "xgb_feature_cols = [\"symbol_id\", \"time_id\"] + CONFIG2.feature_cols\n",
    "\n",
    "\n",
    "# Custom R2 metric for validation\n",
    "def r2_val(y_true, y_pred, sample_weight):\n",
    "    r2 = 1 - np.average((y_pred - y_true) ** 2, weights=sample_weight) / (np.average((y_true) ** 2, weights=sample_weight) + 1e-38)\n",
    "    return r2\n",
    "\n",
    "\n",
    "class NN(LightningModule):\n",
    "    def __init__(self, input_dim, hidden_dims, dropouts, lr, weight_decay):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        layers = []\n",
    "        in_dim = input_dim\n",
    "        for i, hidden_dim in enumerate(hidden_dims):\n",
    "            layers.append(nn.BatchNorm1d(in_dim))\n",
    "            if i > 0:\n",
    "                layers.append(nn.SiLU())\n",
    "            if i < len(dropouts):\n",
    "                layers.append(nn.Dropout(dropouts[i]))\n",
    "            layers.append(nn.Linear(in_dim, hidden_dim))\n",
    "            # layers.append(nn.ReLU())\n",
    "            in_dim = hidden_dim\n",
    "        layers.append(nn.Linear(in_dim, 1))  # 输出层\n",
    "        layers.append(nn.Tanh())\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.lr = lr\n",
    "        self.weight_decay = weight_decay\n",
    "        self.validation_step_outputs = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        return 5 * self.model(x).squeeze(-1)  # 输出为一维张量\n",
    "\n",
    "    def training_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w  # 考虑样本权重\n",
    "        loss = loss.mean()\n",
    "        self.log('train_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        x, y, w = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.mse_loss(y_hat, y, reduction='none') * w\n",
    "        loss = loss.mean()\n",
    "        self.log('val_loss', loss, on_step=False, on_epoch=True, batch_size=x.size(0))\n",
    "        self.validation_step_outputs.append((y_hat, y, w))\n",
    "        return loss\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        \"\"\"Calculate validation WRMSE at the end of the epoch.\"\"\"\n",
    "        y = torch.cat([x[1] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        if self.trainer.sanity_checking:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "        else:\n",
    "            prob = torch.cat([x[0] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            weights = torch.cat([x[2] for x in self.validation_step_outputs]).cpu().numpy()\n",
    "            # r2_val\n",
    "            val_r_square = r2_val(y, prob, weights)\n",
    "            self.log(\"val_r_square\", val_r_square, prog_bar=True, on_step=False, on_epoch=True)\n",
    "        self.validation_step_outputs.clear()\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=self.weight_decay)\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=5,\n",
    "                                                               verbose=True)\n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'monitor': 'val_loss',\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        if self.trainer.sanity_checking:\n",
    "            return\n",
    "        epoch = self.trainer.current_epoch\n",
    "        metrics = {k: v.item() if isinstance(v, torch.Tensor) else v for k, v in self.trainer.logged_metrics.items()}\n",
    "        formatted_metrics = {k: f\"{v:.5f}\" for k, v in metrics.items()}\n",
    "        print(f\"Epoch {epoch}: {formatted_metrics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5de55116",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:12.381965Z",
     "iopub.status.busy": "2025-01-11T16:04:12.381348Z",
     "iopub.status.idle": "2025-01-11T16:04:12.575183Z",
     "shell.execute_reply": "2025-01-11T16:04:12.574584Z"
    },
    "papermill": {
     "duration": 0.199578,
     "end_time": "2025-01-11T16:04:12.576997",
     "exception": false,
     "start_time": "2025-01-11T16:04:12.377419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "N_folds = 5\n",
    "models = []\n",
    "for fold in range(N_folds):\n",
    "    checkpoint_path = f\"{CONFIG2.model_paths[0]}/nn_{fold}.model\"\n",
    "    model = NN.load_from_checkpoint(checkpoint_path)\n",
    "    models.append(model.to(\"cuda:0\"))\n",
    "\n",
    "lags_ : pl.DataFrame | None = None\n",
    "    \n",
    "def predict_nn_xgb(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    global lags_\n",
    "    if lags is not None:\n",
    "        lags_ = lags\n",
    "\n",
    "    predictions = test.select(\n",
    "        'row_id',\n",
    "        pl.lit(0.0).alias('responder_6'),\n",
    "    )\n",
    "    symbol_ids = test.select('symbol_id').to_numpy()[:, 0]\n",
    "\n",
    "    # add this part to reuse lags of previous date ids when rows have more than 0 time_ids.\n",
    "    lags = lags_.clone().group_by([\"date_id\", \"symbol_id\"], maintain_order=True).last()\n",
    "    test = test.join(lags, on=[\"date_id\", \"symbol_id\"],  how=\"left\")\n",
    "    \n",
    "    \n",
    "    preds = np.zeros((test.shape[0],))\n",
    "    preds += xgb_model.predict(test[xgb_feature_cols].to_numpy()) / 2\n",
    "    test_input = test[CONFIG2.feature_cols].to_pandas()\n",
    "    test_input = test_input.fillna(method = 'ffill').fillna(0)\n",
    "    test_input = torch.FloatTensor(test_input.values).to(\"cuda:0\")\n",
    "    with torch.no_grad():\n",
    "        for i, nn_model in enumerate(tqdm(models)):\n",
    "            nn_model.eval()\n",
    "            preds += nn_model(test_input).cpu().numpy() / 10\n",
    "    # print(f\"predict> preds.shape =\", preds.shape)\n",
    "    \n",
    "    predictions = \\\n",
    "    test.select('row_id').\\\n",
    "    with_columns(\n",
    "        pl.Series(\n",
    "            name   = 'responder_6', \n",
    "            values = np.clip(preds, a_min = -5, a_max = 5),\n",
    "            dtype  = pl.Float64,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12ebe58e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:12.585165Z",
     "iopub.status.busy": "2025-01-11T16:04:12.584491Z",
     "iopub.status.idle": "2025-01-11T16:04:12.589931Z",
     "shell.execute_reply": "2025-01-11T16:04:12.589157Z"
    },
    "papermill": {
     "duration": 0.011101,
     "end_time": "2025-01-11T16:04:12.591521",
     "exception": false,
     "start_time": "2025-01-11T16:04:12.580420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(test: pl.DataFrame, lags: pl.DataFrame | None) -> pl.DataFrame | pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Make ensemble predictions combining all three models:\n",
    "    - Neural Network + XGBoost ensemble\n",
    "    - Starter ensemble (LightGBM + CatBoost + XGBoost)\n",
    "    - Ridge Regression\n",
    "    \n",
    "    Args:\n",
    "        test: DataFrame containing test data\n",
    "        lags: DataFrame containing lagged features\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with final ensemble predictions\n",
    "    \"\"\"\n",
    "    if test['is_scored'].any():\n",
    "        pd_nn_xgb = predict_nn_xgb(test, lags)   \n",
    "        pd_xgb = predict_xgb_stats(test, lags)      \n",
    "        pd_tabm = predict_tabm(test, lags) \n",
    "        pd_win = predict_new(test, lags) \n",
    "    \n",
    "        pred = winppp(pd_nn_xgb,pd_xgb,pd_tabm,pd_win)\n",
    "    \n",
    "    \n",
    "        predictions = test.select('row_id', pl.lit(0.0).alias('responder_6'))\n",
    "        predictions = predictions.with_columns(pl.Series('responder_6', pred.ravel()))\n",
    "    else:\n",
    "        \n",
    "        predictions = pl.DataFrame({'row_id': test['row_id'],'responder_6': 0})\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5951b06",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:12.599004Z",
     "iopub.status.busy": "2025-01-11T16:04:12.598766Z",
     "iopub.status.idle": "2025-01-11T16:04:13.430480Z",
     "shell.execute_reply": "2025-01-11T16:04:13.429509Z"
    },
    "papermill": {
     "duration": 0.839307,
     "end_time": "2025-01-11T16:04:13.434121",
     "exception": false,
     "start_time": "2025-01-11T16:04:12.594814",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import kaggle_evaluation.jane_street_inference_server\n",
    "inference_server = kaggle_evaluation.jane_street_inference_server.JSInferenceServer(predict)\n",
    "\n",
    "if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n",
    "    inference_server.serve()\n",
    "else:\n",
    "    inference_server.run_local_gateway(\n",
    "        (\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/test.parquet',\n",
    "            '/kaggle/input/jane-street-real-time-market-data-forecasting/lags.parquet',\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e2d114f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-11T16:04:13.455837Z",
     "iopub.status.busy": "2025-01-11T16:04:13.455376Z",
     "iopub.status.idle": "2025-01-11T16:04:13.500192Z",
     "shell.execute_reply": "2025-01-11T16:04:13.498294Z"
    },
    "papermill": {
     "duration": 0.060323,
     "end_time": "2025-01-11T16:04:13.504522",
     "exception": false,
     "start_time": "2025-01-11T16:04:13.444199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system(\"rm -rf *.pkl\")\n",
    "os.system(\"rm -rf *.so\")\n",
    "os.system(\"rm -rf *.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0c0af3",
   "metadata": {
    "papermill": {
     "duration": 0.009328,
     "end_time": "2025-01-11T16:04:13.523590",
     "exception": false,
     "start_time": "2025-01-11T16:04:13.514262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9871156,
     "sourceId": 84493,
     "sourceType": "competition"
    },
    {
     "datasetId": 5882430,
     "sourceId": 9640394,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6464763,
     "sourceId": 10444316,
     "sourceType": "datasetVersion"
    },
    {
     "sourceId": 201255000,
     "sourceType": "kernelVersion"
    },
    {
     "sourceId": 203781885,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 30787,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 59.632817,
   "end_time": "2025-01-11T16:04:15.941403",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-01-11T16:03:16.308586",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0329df54bf0d4c69b11886c26fbae2ba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2b0a07c333db4517bc0890d90cd80e9b",
       "max": 5,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_c92778ce65f744e0934b302e3c559bc1",
       "value": 5
      }
     },
     "2b0a07c333db4517bc0890d90cd80e9b": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "386d3b2f595b467ba8c290ade24ec211": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "5590aa9862e7439f849f7bc3cb97167e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_386d3b2f595b467ba8c290ade24ec211",
       "placeholder": "​",
       "style": "IPY_MODEL_75a01e36a2dc447d989e804d33415024",
       "value": " 5/5 [00:00&lt;00:00,  3.64it/s]"
      }
     },
     "75a01e36a2dc447d989e804d33415024": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "7700953db1f94daeb5aaed240016fb92": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_7d61324dd0cb46fb8bb93df30bd662aa",
       "placeholder": "​",
       "style": "IPY_MODEL_8927a41bf55c4c5bbaeecbbbfefd22ec",
       "value": "100%"
      }
     },
     "7d2c58edefdf41bebd6b6a409fb2acb6": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d61324dd0cb46fb8bb93df30bd662aa": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8927a41bf55c4c5bbaeecbbbfefd22ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "b3731331a82c47b1b460f1a18a1842c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_7700953db1f94daeb5aaed240016fb92",
        "IPY_MODEL_0329df54bf0d4c69b11886c26fbae2ba",
        "IPY_MODEL_5590aa9862e7439f849f7bc3cb97167e"
       ],
       "layout": "IPY_MODEL_7d2c58edefdf41bebd6b6a409fb2acb6"
      }
     },
     "c92778ce65f744e0934b302e3c559bc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
